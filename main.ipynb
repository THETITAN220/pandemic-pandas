{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV into a DataFrame\n",
    "df = pd.read_csv('../Datasets/archive/ebola_2014_2016_clean.csv')\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Cases       Deaths\n",
      "count   2477.000000  2485.000000\n",
      "mean    2553.678644  1028.347686\n",
      "std     4427.118148  1656.064372\n",
      "min        0.000000     0.000000\n",
      "25%        1.000000     0.000000\n",
      "50%        8.000000     6.000000\n",
      "75%     3657.000000  2386.000000\n",
      "max    14122.000000  4806.000000\n"
     ]
    }
   ],
   "source": [
    "# Get the summary statistics \n",
    "statistics = df.describe()\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Cases       Deaths\n",
      "count   2477.000000  2485.000000\n",
      "mean    2553.678644  1028.347686\n",
      "std     4427.118148  1656.064372\n",
      "min        0.000000     0.000000\n",
      "25%        1.000000     0.000000\n",
      "50%        8.000000     6.000000\n",
      "75%     3657.000000  2386.000000\n",
      "max    14122.000000  4806.000000\n"
     ]
    }
   ],
   "source": [
    "selected_cols = df.iloc[:, [2,3]]\n",
    "col_stats = selected_cols.describe()\n",
    "print(col_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "normal conditions       1.00      1.00      1.00       235\n",
      "         pandemic       1.00      1.00      1.00       257\n",
      "\n",
      "         accuracy                           1.00       492\n",
      "        macro avg       1.00      1.00      1.00       492\n",
      "     weighted avg       1.00      1.00      1.00       492\n",
      "\n",
      "[[235   0]\n",
      " [  0 257]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../Datasets/archive/ebola_2014_2016_clean.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['dayofweek'] = df['Date'].dt.dayofweek\n",
    "\n",
    "# Feature engineering\n",
    "df['cases_7day_avg'] = df['Cases'].rolling(window=7).mean()\n",
    "df['deaths_7day_avg'] = df['Deaths'].rolling(window=7).mean()\n",
    "\n",
    "# Drop rows with NaN values created by rolling average\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable (example criteria)\n",
    "def classify_status(row):\n",
    "    if row['Cases'] < 50 and row['Deaths'] < 5:\n",
    "        return 'normal conditions'\n",
    "    elif row['Cases'] >= 50 and row['Cases'] < 200:\n",
    "        return 'emergence'\n",
    "    elif row['Cases'] >= 200 and row['Cases'] < 1000:\n",
    "        return 'epidemic'\n",
    "    else:\n",
    "        return 'pandemic'\n",
    "\n",
    "df['status'] = df.apply(classify_status, axis=1)\n",
    "\n",
    "# Define features and target variable\n",
    "features = df[['Cases', 'Deaths', 'cases_7day_avg', 'deaths_7day_avg', 'month', 'day', 'dayofweek']]\n",
    "target = df['status']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "normal conditions       1.00      1.00      1.00       235\n",
      "         pandemic       1.00      1.00      1.00       247\n",
      "\n",
      "         accuracy                           1.00       482\n",
      "        macro avg       1.00      1.00      1.00       482\n",
      "     weighted avg       1.00      1.00      1.00       482\n",
      "\n",
      "[[235   0]\n",
      " [  0 247]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../Datasets/archive/ebola_2014_2016_clean.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "df['date'] = pd.to_datetime(df['Date'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "\n",
    "# Feature engineering\n",
    "df['cases_7day_avg'] = df.groupby('Country')['Cases'].transform(lambda x: x.rolling(window=7).mean())\n",
    "df['deaths_7day_avg'] = df.groupby('Country')['Deaths'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "# Drop rows with NaN values created by rolling average\n",
    "df = df.dropna()\n",
    "\n",
    "# Define the target variable (example criteria)\n",
    "def classify_status(row):\n",
    "    if row['Cases'] < 50 and row['Deaths'] < 5:\n",
    "        return 'normal conditions'\n",
    "    elif row['Cases'] >= 50 and row['Cases'] < 200:\n",
    "        return 'emergence'\n",
    "    elif row['Cases'] >= 200 and row['Cases'] < 1000:\n",
    "        return 'epidemic'\n",
    "    else:\n",
    "        return 'pandemic'\n",
    "\n",
    "df['status'] = df.apply(classify_status, axis=1)\n",
    "\n",
    "# Define features and target variable\n",
    "features = df[['Country', 'Cases', 'Deaths', 'cases_7day_avg', 'deaths_7day_avg', 'month', 'day', 'dayofweek']]\n",
    "target = df['status']\n",
    "\n",
    "# One-hot encode the 'Country' feature\n",
    "features = pd.get_dummies(features, columns=['Country'], drop_first=True)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
